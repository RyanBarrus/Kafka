package com.kafka;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

import org.apache.kafka.clients.CommonClientConfigs;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.common.config.SaslConfigs;

import com.fasterxml.jackson.databind.JsonNode;

import org.apache.avro.file.DataFileReader;
import org.apache.avro.generic.GenericData;

import io.confluent.kafka.serializers.KafkaAvroDecoder;
import io.confluent.kafka.serializers.KafkaAvroDeserializer;
import io.confluent.kafka.serializers.KafkaAvroDeserializerConfig;


public class ConfluentAvroConsumer {
	
	public static void main(String[] args) {
        Properties props = new Properties();
        props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, "pkc-41973.westus2.azure.confluent.cloud:9092");
        props.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
        props.put(SaslConfigs.SASL_MECHANISM, "PLAIN");
        props.put(SaslConfigs.SASL_JAAS_CONFIG, "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"" 
                + GeneralConfig.confluentKey + "\" password=\"" + GeneralConfig.confluentSecret + "\";");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer");
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,  "io.confluent.kafka.serializers.KafkaAvroDeserializer");
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "consumerGroup1");
        
        
        props.put(KafkaAvroDeserializerConfig.SPECIFIC_AVRO_READER_CONFIG, false);
        props.put(KafkaAvroDeserializerConfig.SCHEMA_REGISTRY_URL_CONFIG, "https://psrc-4r0k9.westus2.azure.confluent.cloud");
        props.put(KafkaAvroDeserializerConfig.BASIC_AUTH_CREDENTIALS_SOURCE,"USER_INFO");
        props.put(KafkaAvroDeserializerConfig.USER_INFO_CONFIG, GeneralConfig.confluentSchemaRegistryKey 
        		+ ":" + GeneralConfig.confluentSchemaRegistrySecret);

        KafkaConsumer<String, JsonNode> consumer = new KafkaConsumer<String, JsonNode>(props);
        
        consumer.subscribe(Arrays.asList("Race"));
        
        
        try {
			while (true) {
				ConsumerRecords<String, JsonNode> records = consumer.poll(Duration.ofMillis(1000));
				for (ConsumerRecord<String, JsonNode> record : records) {
					
					System.out.println(record);
					
					System.out.println(record.value().get("value"));
					
					JsonNode jsonNode = record.value().get("value");
					
					
					
					System.out.println("test");
					

					System.out.println(jsonNode);
					
				}
				
			}
		} catch (Exception e) {
			System.out.println(("Exception occured while consuming messages" + e));
		}finally {
			consumer.close();
		}
        
    }
	
}
